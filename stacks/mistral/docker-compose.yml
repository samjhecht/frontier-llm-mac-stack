# Docker Compose configuration for Mistral.rs
# Includes common monitoring services from ../common/monitoring/docker-compose.yml

include:
  - ../common/monitoring/docker-compose.yml

services:
  # Mistral.rs Inference Server
  mistral:
    build:
      context: ./docker
      dockerfile: Dockerfile
    image: frontier-mistral:latest
    container_name: frontier-mistral
    restart: unless-stopped
    ports:
      - "${MISTRAL_API_PORT:-8080}:8080"
    volumes:
      - mistral-models:/models
      - ./config/mistral:/config
    environment:
      - RUST_LOG=${MISTRAL_LOG_LEVEL:-info}
      - MISTRAL_MODEL_PATH=/models
      - MISTRAL_PORT=${MISTRAL_API_PORT:-8080}
      - MISTRAL_HOST=0.0.0.0
      - MISTRAL_MAX_BATCH_SIZE=${MISTRAL_MAX_BATCH_SIZE:-8}
      - MISTRAL_MODEL_TYPE=${MISTRAL_MODEL_TYPE:-plain}
      - MISTRAL_MODEL_ID=${MISTRAL_MODEL_ID:-${DEFAULT_MODEL}}
      - MISTRAL_USE_V5_MODE=${MISTRAL_USE_V5_MODE:-true}
    # Command is handled by docker-entrypoint.sh based on environment variables
    # To use config.toml, set MISTRAL_MODEL_TYPE=toml and mount config at /models/config.toml
    deploy:
      resources:
        limits:
          memory: ${MISTRAL_MEMORY_LIMIT:-64G}
        reservations:
          memory: ${MISTRAL_MEMORY_RESERVATION:-32G}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:${MISTRAL_API_PORT:-8080}/health"]
      interval: ${MISTRAL_HEALTH_INTERVAL:-30s}
      timeout: ${MISTRAL_HEALTH_TIMEOUT:-10s}
      retries: ${MISTRAL_HEALTH_RETRIES:-3}
      start_period: ${MISTRAL_HEALTH_START_PERIOD:-60s}
    networks:
      - frontier-llm-network
      - frontier-monitoring
    logging:
      driver: "json-file"
      options:
        max-size: ${MISTRAL_LOG_MAX_SIZE:-10m}
        max-file: ${MISTRAL_LOG_MAX_FILE:-3}

  # Ollama API Compatibility Proxy
  mistral-ollama-proxy:
    build:
      context: ./api-proxy
      dockerfile: Dockerfile
    image: frontier-mistral-ollama-proxy:latest
    container_name: frontier-mistral-ollama-proxy
    restart: unless-stopped
    ports:
      - "${OLLAMA_API_PORT:-11434}:11434"
    environment:
      - RUST_LOG=${PROXY_LOG_LEVEL:-info}
      - MISTRAL_URL=http://mistral:8080
      - BIND_ADDRESS=0.0.0.0:11434
    depends_on:
      - mistral
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - frontier-llm-network
    logging:
      driver: "json-file"
      options:
        max-size: 10m
        max-file: 3

volumes:
  mistral-models:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ${MISTRAL_MODELS_PATH:-./data/mistral-models}

networks:
  frontier-llm-network:
    external: true
  frontier-monitoring:
    name: frontier-monitoring
    external: true